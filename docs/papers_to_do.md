
| #  | Year | Algorithm Name                        | Paper Title                                                                                  | Paper Link                                                | Code Path | Description | Complexity | Variants | Notes |
|----|------|---------------------------------------|----------------------------------------------------------------------------------------------|-----------------------------------------------------------|-----------|-------------|------------|----------|-------|
| 1  | 1989 | Q-Learning                            | "Learning from Delayed Rewards"                                                              | [Link](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)    |           |             |            |          |       |
| 2  | 1994 | SARSA                                 | "On-line Q-Learning using Connectionist Systems"                                             | [Link](https://link.springer.com/chapter/10.1007/3-540-60552-4_30) |        |           |             |            |          |       |
| 3  | 1940s-1990s | Monte Carlo Methods            | Various                                                                                      |                                                           |           |             |            |          |       |
| 4  | 1988 | Temporal Difference (TD) Learning     | "Learning to Predict by the Methods of Temporal Differences"                                 | [Link](https://www.jair.org/index.php/jair/article/view/101) |           |             |            |          |       |
| 5  | 1960 | Policy Iteration                      | "Dynamic Programming and Markov Processes"                                                   |                                                           |           |             |            |          |       |
| 6  | 1957 | Value Iteration                       | "A Markovian Decision Process"                                                               |                                                           |           |             |            |          |       |
| 7  | 1988 | TD(Î»)                                 | "Learning to Predict by the Methods of Temporal Differences"                                 | [Link](https://www.jair.org/index.php/jair/article/view/101) |           |             |            |          |       |
| 8  | 2006 | Monte Carlo Tree Search (MCTS)        | "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search"                      | [Link](https://link.springer.com/chapter/10.1007/978-3-540-75538-0_14) |           |             |            |          |       |
| 9  | 1983 | Actor-Critic Methods                  | "Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problems"            | [Link](https://ieeexplore.ieee.org/document/6313077)      |           |             |            |          |       |
| 10 | 1995 | TD-Gammon                             | "Temporal Difference Learning and TD-Gammon"                                                 | [Link](https://www.science.org/doi/10.1126/science.257.5066.920) |           |             |            |          |       |
| 11 | 2015 | Deep Q-Networks (DQN)                 | "Human-level control through deep reinforcement learning"                                    | [Link](https://www.nature.com/articles/nature14236)       |           |             |            |          |       |
| 12 | 2016 | Double DQN                            | "Deep Reinforcement Learning with Double Q-learning"                                         | [Link](https://arxiv.org/abs/1509.06461)                  |           |             |            |          |       |
| 13 | 2016 | Dueling DQN                           | "Dueling Network Architectures for Deep Reinforcement Learning"                              | [Link](https://arxiv.org/abs/1511.06581)                  |           |             |            |          |       |
| 14 | 2015 | Prioritized Experience Replay         | "Prioritized Experience Replay"                                                              | [Link](https://arxiv.org/abs/1511.05952)                  |           |             |            |          |       |
| 15 | 2016 | A3C (Asynchronous Advantage Actor-Critic) | "Asynchronous Methods for Deep Reinforcement Learning"                                     | [Link](https://arxiv.org/abs/1602.01783)                  |           |             |            |          |       |
| 16 | 2017 | PPO (Proximal Policy Optimization)    | "Proximal Policy Optimization Algorithms"                                                    | [Link](https://arxiv.org/abs/1707.06347)                  |           |             |            |          |       |
| 17 | 2015 | TRPO (Trust Region Policy Optimization) | "Trust Region Policy Optimization"                                                         | [Link](https://arxiv.org/abs/1502.05477)                  |           |             |            |          |       |
| 18 | 2015 | DDPG (Deep Deterministic Policy Gradient) | "Continuous control with deep reinforcement learning"                                      | [Link](https://arxiv.org/abs/1509.02971)                  |           |             |            |          |       |
| 19 | 2018 | SAC (Soft Actor-Critic)               | "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor" | [Link](https://arxiv.org/abs/1801.01290) |           |             |            |          |       |
| 20 | 2017 | Rainbow DQN                           | "Rainbow: Combining Improvements in Deep Reinforcement Learning"                             | [Link](https://arxiv.org/abs/1710.02298)                  |           |             |            |          |       |
| 21 | 2002 | NEAT (NeuroEvolution of Augmenting Topologies) | "Evolving Neural Networks through Augmenting Topologies"                                   | [Link](https://dl.acm.org/doi/10.1162/106365602320169811) |           |             |            |          |       |
| 22 | 2003 | CMA-ES (Covariance Matrix Adaptation Evolution Strategy) | "The CMA Evolution Strategy: A Comparing Review"                                        | [Link](https://link.springer.com/article/10.1007/s00421-005-1404-1) |           |             |            |          |       |
| 23 | 2015 | GAE (Generalized Advantage Estimation) | "High-Dimensional Continuous Control Using Generalized Advantage Estimation"                  | [Link](https://arxiv.org/abs/1506.02438)                  |           |             |            |          |       |
| 24 | 1990 | Dyna-Q                               | "Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming" | [Link](https://dl.acm.org/doi/10.5555/89119.89127) |           |             |            |          |       |
| 25 | Various | Model Predictive Control (MPC)    | Various                                                                                      |                                                           |           |             |            |          |       |
| 26 | 2019 | MBPO (Model-Based Policy Optimization) | "When to Trust Your Model: Model-Based Policy Optimization"                                 | [Link](https://arxiv.org/abs/1906.08253)                  |           |             |            |          |       |
| 27 | 2019 | PlaNet                               | "PlaNet: A Deep Planning Network for Reinforcement Learning"                                 | [Link](https://arxiv.org/abs/1811.04551)                  |           |             |            |          |       |
| 28 | 2020 | Dreamer                              | "Dream to Control: Learning Behaviors by Latent Imagination"                                 | [Link](https://arxiv.org/abs/1912.01603)                  |           |             |            |          |       |
| 29 | 2018 | World Models                         | "World Models"                                                                               | [Link](https://arxiv.org/abs/1803.10122)                  |           |             |            |          |       |
| 30 | 2019 | MuZero                               | "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model"                      | [Link](https://arxiv.org/abs/1911.08265)                  |           |             |            |          |       |
| 31 | 2017 | MADDPG (Multi-Agent DDPG)            | "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"                    | [Link](https://arxiv.org/abs/1706.02275)                  |           |             |            |          |       |
| 32 | 2018 | QMIX                                 | "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning"    | [Link](https://arxiv.org/abs/1803.11485)                  |           |             |            |          |       |
| 33 | 2018 | COMA (Counterfactual Multi-Agent Policy Gradients) | "Counterfactual Multi-Agent Policy Gradients"                                        | [Link](https://arxiv.org/abs/1705.08926)                  |           |             |            |          |       |
| 34 | 2017 | VDN (Value-Decomposition Networks)   | "Value-Decomposition Networks For Cooperative Multi-Agent Learning"                          | [Link](https://arxiv.org/abs/1706.05296)                  |           |             |            |          |      

 |
| 35 | 2021 | M3DDPG                               | "Reinforcement Learning with Monte Carlo Policy Evaluation"                                  | [Link](https://arxiv.org/abs/1710.06764)                  |           |             |            |          |       |
| 36 | 2016 | H-DQN (Hierarchical DQN)             | "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation" | [Link](https://arxiv.org/abs/1604.06057) |           |             |            |          |       |
| 37 | 2017 | Option-Critic Architecture           | "Option-Critic Architecture"                                                                | [Link](https://arxiv.org/abs/1609.05140)                  |           |             |            |          |       |
| 38 | 2017 | MAML (Model-Agnostic Meta-Learning)  | "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"                          | [Link](https://arxiv.org/abs/1703.03400)                  |           |             |            |          |       |
| 39 | 2016 | RL^2                                 | "RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning"                          | [Link](https://arxiv.org/abs/1611.02779)                  |           |             |            |          |       |
| 40 | 2019 | PEARL (Probabilistic Embeddings for Actor-Critic RL) | "PEARL: Efficient Off-Policy Meta-Reinforcement Learning" | [Link](https://arxiv.org/abs/1903.08254)                  |           |             |            |          |       |
| 41 | 1998 | Bayesian Q-Learning                  | "Bayesian Q-Learning"                                                                       | [Link](https://dl.acm.org/doi/10.5555/294199.294279)      |           |             |            |          |       |
| 42 | 2015 | Bayesian Policy Optimization         | "Bayesian Policy Optimization"                                                              | [Link](https://arxiv.org/abs/1502.05477)                  |           |             |            |          |       |
| 43 | 2018 | Exploration via Random Network Distillation (RND) | "Exploration by Random Network Distillation"                                       | [Link](https://arxiv.org/abs/1810.12894)                  |           |             |            |          |       |
| 44 | 2017 | Intrinsic Curiosity Module (ICM)     | "Curiosity-driven Exploration by Self-supervised Prediction"                                 | [Link](https://arxiv.org/abs/1705.05363)                  |           |             |            |          |       |
| 45 | 1933 | Thompson Sampling                    | "Thompson Sampling: An Overview and Recent Advances"                                        | [Link](https://arxiv.org/abs/1707.02038)                  |           |             |            |          |       |
| 46 | 2002 | UCB1 (Upper Confidence Bound)        | "A Finite-Time Analysis of the Multiarmed Bandit Problem"                                   | [Link](https://dl.acm.org/doi/10.5555/944919.944941)      |           |             |            |          |       |
| 47 | 2016 | Count-Based Exploration              | "Count-Based Exploration with Neural Density Models"                                        | [Link](https://arxiv.org/abs/1707.02038)                  |           |             |            |          |       |
| 48 | 2018 | NoisyNet                             | "Noisy Networks for Exploration"                                                            | [Link](https://arxiv.org/abs/1706.10295)                  |           |             |            |          |       |
| 49 | 2016 | Bootstrapped DQN                     | "Deep Exploration via Bootstrapped DQN"                                                     | [Link](https://arxiv.org/abs/1602.04621)                  |           |             |            |          |       |
| 50 | 2019 | Exploration via Latent Learning      | "Episodic Curiosity through Reachability"                                                   | [Link](https://arxiv.org/abs/1807.02812)                  |           |             |            |          |       |
| 51 | 1992 | REINFORCE                            | "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"  | [Link](https://dl.acm.org/doi/10.5555/119868.119876)      |           |             |            |          |       |
| 52 | 1981 | Importance Sampling                  | "Importance Sampling for Reinforcement Learning with Off-Policy Temporal-Difference Learning" | [Link](https://dl.acm.org/doi/10.5555/1141089.1141092)   |           |             |            |          |       |
| 53 | 2012 | Off-Policy Actor-Critic              | "Off-Policy Actor-Critic"                                                                   | [Link](https://dl.acm.org/doi/10.5555/3305381.3305518)    |           |             |            |          |       |
| 54 | 2017 | Soft Q-Learning                      | "Soft Q-Learning with Boltzmann Exploration"                                                | [Link](https://arxiv.org/abs/1702.03006)                  |           |             |            |          |       |
| 55 | 2018 | Twin Delayed DDPG (TD3)              | "Addressing Function Approximation Error in Actor-Critic Methods"                           | [Link](https://arxiv.org/abs/1802.09477)                  |           |             |            |          |       |
| 56 | 2000 | Off-Policy Monte Carlo Methods       | "Off-Policy Monte Carlo Control with Function Approximation"                                | [Link](https://dl.acm.org/doi/10.5555/3000579.3000726)    |           |             |            |          |       |
| 57 | 2003 | Batch Constrained Q-Learning (BCQ)   | "Batch Constrained Deep Q-Learning"                                                         | [Link](https://arxiv.org/abs/1910.01708)                  |           |             |            |          |       |
| 58 | 1989 | Behavior Cloning                     | "Learning from Demonstrations"                                                              | [Link](https://dl.acm.org/doi/10.5555/3305381.3305518)    |           |             |            |          |       |
| 59 | 1994 | N-step Q-Learning                    | "A Convergence Analysis of Q-Learning Algorithms with Q-Function Approximation"             | [Link](https://dl.acm.org/doi/10.5555/1030960.1030970)    |           |             |            |          |       |
| 60 | 2018 | AlphaZero                            | "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"    | [Link](https://arxiv.org/abs/1712.01815)                  |           |             |            |          |       |
| 61 | 2012 | MuJoCo (Multi-Joint dynamics with Contact) | "MuJoCo: A Physics Engine for Model-Based Control"                                    | [Link](https://www.mujoco.org/book/book.pdf)              |           |             |            |          |       |
| 62 | 2016 | AlphaGo                              | "Mastering the Game of Go with Deep Neural Networks and Tree Search"                        | [Link](https://www.nature.com/articles/nature16961)       |           |             |            |          |       |
| 63 | 2016 | GAIL (Generative Adversarial Imitation Learning) | "Generative Adversarial Imitation Learning"                                           | [Link](https://arxiv.org/abs/1606.03476)                  |           |             |            |          |       |
| 64 | 2017 | HER (Hindsight Experience Replay)    | "Hindsight Experience Replay"                                                               | [Link](https://arxiv.org/abs/1707.01495)                  |           |             |            |          |       |
| 65 | 2018 | IMPALA (Importance Weighted Actor-Learner Architecture) | "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures" | [Link](https://arxiv.org/abs/1802.01561) |           |             |            |          |       |
| 66 | 2020 | IMP (Information Maximizing Policy)  | "Information Maximizing Policy for Reinforcement Learning"                                  | [Link](https://arxiv.org/abs/2004.01523)                  |           |             |            |          |       |
| 67 | 2018 | PETS (Probabilistic Ensembles with Trajectory Sampling) | "Probabilistic Model-Based Reinforcement Learning with Trajectory Sampling"            | [Link](https://arxiv.org/abs/1810.01112)                  |           |             |            |          |       |
| 68 | 2018 | QT-Opt                               | "QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation"        | [Link](https://arxiv.org/abs/1806

.10293)                  |           |             |            |          |       |
| 69 | 2019 | Batch-Constrained Deep Q-Learning (BCQ) | "Batch-Constrained Q-Learning"                                                        | [Link](https://arxiv.org/abs/1910.01708)                  |           |             |            |          |       |
| 70 | 1999 | CEM (Cross-Entropy Method)           | "The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation, and Machine Learning" | [Link](https://link.springer.com/article/10.1007/BF02288368) |           |             |            |          |       |
| 71 | 2018 | MPO (Maximum a Posteriori Policy Optimization) | "Maximum a Posteriori Policy Optimization"                                        | [Link](https://arxiv.org/abs/1806.06920)                  |           |             |            |          |       |
| 72 | 2007 | CACLA (Continuous Actor-Critic Learning Automaton) | "Actor-Critic Learning with Application to Robotics"                                | [Link](https://ieeexplore.ieee.org/document/6313077)      |           |             |            |          |       |
| 73 | 2000 | Policy Gradient Methods              | "Policy Gradient Methods for Reinforcement Learning with Function Approximation"            | [Link](https://dl.acm.org/doi/10.5555/3000579.3000726)    |           |             |            |          |       |
| 74 | 2010 | REPS (Relative Entropy Policy Search) | "Relative Entropy Policy Search"                                                            | [Link](https://link.springer.com/article/10.1007/s10994-010-5237-4) |           |             |            |          |       |
| 75 | 2021 | Go-Explore                           | "First return, then explore"                                                               | [Link](https://arxiv.org/abs/1906.04556)                  |           |             |            |          |       |
| 76 | 2020 | Plan2Explore                         | "Plan2Explore: Towards Large-Scale Active Learning"                                        | [Link](https://arxiv.org/abs/2005.05960)                  |           |             |            |          |       |
| 77 | 2020s | MuJoCo MPC                          | "MuJoCo MPC: Model Predictive Control for MuJoCo Environments"                              | [Link](https://www.mujoco.org/book/book.pdf)              |           |             |            |          |       |
| 78 | 2019 | AlphaStar                            | "AlphaStar: Mastering the Real-Time Strategy Game StarCraft II"                            | [Link](https://deepmind.com/research/case-studies/alphastar-mastering-the-real-time-strategy-game-starcraft-ii) |           |             |            |          |       |
| 79 | 2020 | AlphaFold                            | "AlphaFold: A Solution to the Protein Folding Problem"                                     | [Link](https://www.nature.com/articles/s41586-019-1923-7) |           |             |            |          |       |
| 80 | 2021 | DreamerV2                            | "Mastering Diverse Domains through World Models"                                           | [Link](https://arxiv.org/abs/2301.04104)                  |           |             |            |          |       |
| 81 | 2020s | AGI-Safe                            | "Safe Reinforcement Learning for AGI Systems"                                              | [Link](https://arxiv.org/abs/1905.11960)                  |           |             |            |          |       |
| 82 | 2020s | Offline RL (CQL, BRAC, etc.)        | "Conservative Q-Learning for Offline Reinforcement Learning"                               | [Link](https://arxiv.org/abs/2006.04779)                  |           |             |            |          |       |
| 83 | 2019 | MAVEN (Multi-Agent Variational Exploration) | "Multi-Agent Variational Exploration"                                                | [Link](https://arxiv.org/abs/1910.07483)                  |           |             |            |          |       |
| 84 | 2020s | Cooperative MARL                    | "Cooperative Multi-Agent Reinforcement Learning"                                           | [Link](https://arxiv.org/abs/1702.03037)                  |           |             |            |          |       |
| 85 | 2020s | MELD (Maximum Entropy Learning with Discriminators) | "MELD: Maximum Entropy Learning with Discriminators"                             | [Link](https://arxiv.org/abs/2007.02286)                  |           |             |            |          |       |
| 86 | 2017 | Wasserstein GANs                     | "Wasserstein GAN"                                                                          | [Link](https://arxiv.org/abs/1701.07875)                  |           |             |            |          |       |
| 87 | 2020s | DDO (Deep Delayed Optimization)     | "Deep Delayed Optimization"                                                                | [Link](https://arxiv.org/abs/2003.08224)                  |           |             |            |          |       |
| 88 | 2020s | PI-SRL (Policy Iteration State Regularization) | "Policy Iteration with State Regularization in RL"                                  | [Link](https://arxiv.org/abs/1911.12344)                  |           |             |            |          |       |
| 89 | 2020s | Scalable RL                         | "Scalable Reinforcement Learning Algorithms"                                               | [Link](https://arxiv.org/abs/2002.12348)                  |           |             |            |          |       |
| 90 | 1992 | Experience Replay                    | "The Rehearsal Problem for Reinforcement Learning"                                         | [Link](https://dl.acm.org/doi/10.5555/1622826.1622835)    |           |             |            |          |       |
| 91 | 2015 | Target Networks                      | "Deep Q-Learning with Target Networks"                                                     | [Link](https://arxiv.org/abs/1509.06461)                  |           |             |            |          |       |
| 92 | 1999 | Reward Shaping                       | "Potential-Based Shaping and Q-Value Initialization are Equivalent"                        | [Link](https://www.aaai.org/Papers/ICML/1999/ICML99-008.pdf) |           |             |            |          |       |
| 93 | 2000 | Inverse RL                           | "Algorithms for Inverse Reinforcement Learning"                                            | [Link](https://dl.acm.org/doi/10.5555/1622826.1622835)    |           |             |            |          |       |
| 94 | 2009 | Curriculum Learning                  | "Curriculum Learning"                                                                      | [Link](https://www.jmlr.org/papers/volume9/bengio07a/bengio07a.pdf) |           |             |            |          |       |
| 95 | 1998 | Hierarchical Reinforcement Learning  | "Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition"            | [Link](https://arxiv.org/abs/cs/9905014)                  |           |             |            |          |       |
| 96 | 2020s | Multitask RL                        | "Multitask Reinforcement Learning with Soft Modularization"                                | [Link](https://arxiv.org/abs/2003.12655)                  |           |             |            |          |       |
| 97 | 2017 | Adversarial RL                       | "Adversarial Reinforcement Learning"                                                       | [Link](https://arxiv.org/abs/1703.02702)                  |           |             |            |          |       |
| 98 | 2020s | Human-in-the-Loop RL                | "Human-in-the-Loop Reinforcement Learning"                                                 | [Link](https://arxiv.org/abs/2006.15016)                  |           |             |            |          |       |
| 99 | 2015 | Safe RL                              | "Safe Reinforcement Learning"                                                              | [Link](https://arxiv.org/abs/1507.05796)                  |           |             |            |          |       |
| 100| 2020s | AGI-Safe                            | "Safe Reinforcement Learning for AGI Systems"                                              | [Link](https://arxiv.org/abs/1905.11960)                  |           |             |            |          |       |

