# Reinforcement Learning ![](https://img.shields.io/github/stars/Tony-Tan/Reinforcement-Learning?style=social)
This project has been supported by 
[jetbrains](https://www.jetbrains.com/) 


[![](./jetbrains-variant-2.png)](https://www.jetbrains.com/) 

You can find my blog and research notes on: [![website_online](./logo_online.png)](https://anthony-tan.com)

or follow my twitter: 
[![Twitter Follow](https://img.shields.io/twitter/follow/anthony_tan?color=1DA1F2&logo=twitter&style=for-the-badge)](https://twitter.com/anthony_s_tan)


## This Project Contains All Experiment Codes of the Paper I've Read
<!----![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F________________%3Ffields%3DcitationCount)--->

| No  | Year | Name                                                                                                             |                                                                                                      Citations                                                                                                       |
|:---:|:----:|:-----------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
|  1  | 1951 | [A Stochastic Approximation Method](./Robbins-Monro_Method)                                                      | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F34ddd8865569c2c32dec9bf7ffc817ff42faaa01%3Ffields%3DcitationCount) | 
|  2  | 1986 | [Stochastic approximation for Monte Carlo optimization](./Stochastic_Approximation_for_Monte_Carlo_Optimization) | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F08bcd967e6ca896eb85d6e03561aabf138df65d1%3Ffields%3DcitationCount) |  
|  3  | 2001 | [A natural policy gradient](./trpo_npg)                                                                          | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb18833db0de9393d614d511e60821a1504fc6cd1%3Ffields%3DcitationCount) |
|  4  | 2013 | [Playing Atari with Deep Reinforcement Learning](./dqn)                                                          | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2319a491378867c7049b3da055c5df60e1671158%3Ffields%3DcitationCount) | 
|  5  | 2015 | [Human-level control through deep reinforcement learning](./dqn)                                                 | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe0e9a94c4a6ba219e768b4e59f72c18f0a22e23d%3Ffields%3DcitationCount) |
|  6  | 2015 | [Trust Region Policy Optimization](./trpo_npg)                                                                   | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F66cdc28dc084af6507e979767755e99fe0b46b39%3Ffields%3DcitationCount) |
|  7  | 2015 | [Continuous control with deep reinforcement learning](./DDPG)                                                    | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F024006d4c2a89f7acacc6e4438d156525b60a98f%3Ffields%3DcitationCount) |
|  8  | 2016 | [Dueling Network Architectures for Deep Reinforcement Learning](./dueling_network)                               | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F4c05d7caa357148f0bbd61720bdd35f0bc05eb81%3Ffields%3DcitationCount) |
|  9  | 2016 | [Prioritized Experience Replay](./proportional_prioritization)                                                   | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc6170fa90d3b2efede5a2e1660cb23e1c824f2ca%3Ffields%3DcitationCount) |
| 10  | 2017 | [Proximal Policy Optimization Algorithms](./ppo)                                                                 | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdce6f9d4017b1785979e7520fd0834ef8cf02f4b%3Ffields%3DcitationCount) |
| 11  | 2018 | [Addressing Function Approximation Error in Actor-Critic Methods](./TD3)                                         | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F4debb99c0c63bfaa97dd433bc2828e4dac81c48b%3Ffields%3DcitationCount) |
| 12  | 2018 | [Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](./SAC)       | ![](https://img.shields.io/badge/dynamic/json?label=Citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F811df72e210e20de99719539505da54762a11c6d%3Ffields%3DcitationCount) |







## Map of Reinforcement Learning Algorithms
[./doc/Maps](doc/Maps) contains all maps of concepts in RL that are coded by graphviz language.
Command on OS X with graphviz:
<code>dot the-name-of-your-dot-file.dot -Tsvg -o output-file-name.svg</code>


### Concepts in 'Reinforcement Learning: an Introduction'
![](doc/Maps/RLAI.svg)


### Graph of DQN papers
![](doc/Maps/DQN_graph.svg)


### Graph of PG papers
![](doc/Maps/PG_graph.svg)